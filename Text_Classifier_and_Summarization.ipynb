{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNPgaLFf1L5TcALt2q3kM7u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riyansh08/NLP_TextClassifier/blob/main/Text_Classifier_and_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WE WILL GET THE DATA FIRST. DATASET USED IS - PubMed 200K RCT DATASET"
      ],
      "metadata": {
        "id": "qyvbNX1lCPLQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCXGNDVG6nb-",
        "outputId": "b04eeb45-725d-4018-d9d1-0bcf6c725f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/14)\u001b[K\rremote: Counting objects:  14% (2/14)\u001b[K\rremote: Counting objects:  21% (3/14)\u001b[K\rremote: Counting objects:  28% (4/14)\u001b[K\rremote: Counting objects:  35% (5/14)\u001b[K\rremote: Counting objects:  42% (6/14)\u001b[K\rremote: Counting objects:  50% (7/14)\u001b[K\rremote: Counting objects:  57% (8/14)\u001b[K\rremote: Counting objects:  64% (9/14)\u001b[K\rremote: Counting objects:  71% (10/14)\u001b[K\rremote: Counting objects:  78% (11/14)\u001b[K\rremote: Counting objects:  85% (12/14)\u001b[K\rremote: Counting objects:  92% (13/14)\u001b[K\rremote: Counting objects: 100% (14/14)\u001b[K\rremote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25 (from 1)\u001b[K\n",
            "Receiving objects: 100% (39/39), 177.08 MiB | 30.16 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHbeoxv-RnFI",
        "outputId": "29d39dde-2ead-4ce7-c93a-6564522123b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M3NCbVSjRmww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmIRcEO3RuCk",
        "outputId": "4fd70ad8-be0c-4779-a8d1-b2dbeba8ca0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOW IT IS TIME TO PREPROCESS THE DATA"
      ],
      "metadata": {
        "id": "HysUAZLwSlOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lines(filename):\n",
        "  with open(filename , \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "WGJMUumySltN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "AUpoPx8cTUMO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = get_lines(data_dir + \"train.txt\")\n",
        "train_lines[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzpGtKubTVq9",
        "outputId": "9963dd00-9d3e-4433-8ac1-508fed31889b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24491034\\n',\n",
              " 'BACKGROUND\\tThe emergence of HIV as a chronic condition means that people living with HIV are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments .\\n',\n",
              " 'BACKGROUND\\tThis paper describes the design and evaluation of Positive Outlook , an online program aiming to enhance the self-management skills of gay men living with HIV .\\n',\n",
              " 'METHODS\\tThis study is designed as a randomised controlled trial in which men living with HIV in Australia will be assigned to either an intervention group or usual care control group .\\n',\n",
              " \"METHODS\\tThe intervention group will participate in the online group program ` Positive Outlook ' .\\n\",\n",
              " 'METHODS\\tThe program is based on self-efficacy theory and uses a self-management approach to enhance skills , confidence and abilities to manage the psychosocial issues associated with HIV in daily life .\\n',\n",
              " 'METHODS\\tParticipants will access the program for a minimum of @ minutes per week over seven weeks .\\n',\n",
              " 'METHODS\\tPrimary outcomes are domain specific self-efficacy , HIV related quality of life , and outcomes of health education .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  input_lines = get_lines(filename)\n",
        "  abstract_lines = \"\"\n",
        "  abstract_samples = []\n",
        "\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"):\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\"\n",
        "    elif line.isspace():\n",
        "      abstract_line_split = abstract_lines.splitlines()\n",
        "\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data ={}\n",
        "        target_text_split = abstract_line.split(\"\\t\")\n",
        "        line_data[\"target\"] = target_text_split[0]\n",
        "        line_data[\"text\"] = target_text_split[1].lower()\n",
        "        line_data[\"line_number\"] = abstract_line_number\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split)\n",
        "        abstract_samples.append(line_data)\n",
        "    else:\n",
        "      abstract_lines += line\n",
        "  return abstract_samples\n",
        "\n"
      ],
      "metadata": {
        "id": "eX-Db-_nUj2M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation set\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3T7ggDdVGRV",
        "outputId": "e06f477b-8733-4a65-b75a-d0d23af77119"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(752231, 28932, 29493)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfV3LscCW38G",
        "outputId": "03d809d9-a7d2-4623-c9f0-6c7f8805d612"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'BACKGROUND',\n",
              "  'text': 'the emergence of hiv as a chronic condition means that people living with hiv are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'this paper describes the design and evaluation of positive outlook , an online program aiming to enhance the self-management skills of gay men living with hiv .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'this study is designed as a randomised controlled trial in which men living with hiv in australia will be assigned to either an intervention group or usual care control group .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': \"the intervention group will participate in the online group program ` positive outlook ' .\",\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'the program is based on self-efficacy theory and uses a self-management approach to enhance skills , confidence and abilities to manage the psychosocial issues associated with hiv in daily life .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'participants will access the program for a minimum of @ minutes per week over seven weeks .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'primary outcomes are domain specific self-efficacy , hiv related quality of life , and outcomes of health education .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcomes include : depression , anxiety and stress ; general health and quality of life ; adjustment to hiv ; and social support .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOW WE WILL TURN THE DICTIONARIES INTO PANDAS DATAFRAME . ML MODELS WORK THE BEST WITH PANDAS DATAFRAME BECAUSE THEY ARE MOREF STRUCTURED."
      ],
      "metadata": {
        "id": "VaIbCwp3XLV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "tzdZKB54XVnG",
        "outputId": "99db75c0-24a8-48da-e33f-46a163dc230e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0    BACKGROUND  the emergence of hiv as a chronic condition me...   \n",
              "1    BACKGROUND  this paper describes the design and evaluation...   \n",
              "2       METHODS  this study is designed as a randomised control...   \n",
              "3       METHODS  the intervention group will participate in the...   \n",
              "4       METHODS  the program is based on self-efficacy theory a...   \n",
              "5       METHODS  participants will access the program for a min...   \n",
              "6       METHODS  primary outcomes are domain specific self-effi...   \n",
              "7       METHODS  secondary outcomes include : depression , anxi...   \n",
              "8       METHODS  data collection will take place at baseline , ...   \n",
              "9   CONCLUSIONS  results of the positive outlook study will pro...   \n",
              "10   BACKGROUND                                           actrn@ .   \n",
              "11   BACKGROUND  the aim of this study was to evaluate the effi...   \n",
              "12      METHODS  a total of @ patients suffering from thyroid o...   \n",
              "13      METHODS  patients were randomized into two groups : gro...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11            0           12  \n",
              "12            1           12  \n",
              "13            2           12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c63416f-8863-476a-bacb-5aec1dbfa675\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>the emergence of hiv as a chronic condition me...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>this paper describes the design and evaluation...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>this study is designed as a randomised control...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>the intervention group will participate in the...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>the program is based on self-efficacy theory a...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>participants will access the program for a min...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>primary outcomes are domain specific self-effi...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcomes include : depression , anxi...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>data collection will take place at baseline , ...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>results of the positive outlook study will pro...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>actrn@ .</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>the aim of this study was to evaluate the effi...</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients suffering from thyroid o...</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>patients were randomized into two groups : gro...</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c63416f-8863-476a-bacb-5aec1dbfa675')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c63416f-8863-476a-bacb-5aec1dbfa675 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c63416f-8863-476a-bacb-5aec1dbfa675');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2384eb72-befc-41bd-800c-d52e18b12581\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2384eb72-befc-41bd-800c-d52e18b12581')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2384eb72-befc-41bd-800c-d52e18b12581 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_df.total_lines.plot.hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "HfnjNW19X-xu",
        "outputId": "ada1d856-035a-4fc6-95c3-7eb4b7d9ca27"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert abstract text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxvaijNiZw6-",
        "outputId": "5b304bef-6b38-4995-d291-c9d88ee620f0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(752231, 28932, 29493)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHU3nx2rZ0cM",
        "outputId": "4976be78-2493-4b83-cb2c-0b0881ff6f5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the emergence of hiv as a chronic condition means that people living with hiv are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments .',\n",
              " 'this paper describes the design and evaluation of positive outlook , an online program aiming to enhance the self-management skills of gay men living with hiv .',\n",
              " 'this study is designed as a randomised controlled trial in which men living with hiv in australia will be assigned to either an intervention group or usual care control group .',\n",
              " \"the intervention group will participate in the online group program ` positive outlook ' .\",\n",
              " 'the program is based on self-efficacy theory and uses a self-management approach to enhance skills , confidence and abilities to manage the psychosocial issues associated with hiv in daily life .',\n",
              " 'participants will access the program for a minimum of @ minutes per week over seven weeks .',\n",
              " 'primary outcomes are domain specific self-efficacy , hiv related quality of life , and outcomes of health education .',\n",
              " 'secondary outcomes include : depression , anxiety and stress ; general health and quality of life ; adjustment to hiv ; and social support .',\n",
              " 'data collection will take place at baseline , completion of the intervention ( or eight weeks post randomisation ) and at @ week follow-up .',\n",
              " 'results of the positive outlook study will provide information regarding the effectiveness of online group programs improving health related outcomes for men living with hiv .']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAKE NUMERIC LABELS (ML MODELS REQUIRE NUMERIC LABELS)"
      ],
      "metadata": {
        "id": "hsYWDxvrZ4wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "8HncmhARZ_GX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB_xCO0TfpJb",
        "outputId": "fe6cb520-8e51-4f28-9348-beafb7408332"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HTd4OZVf3ey",
        "outputId": "fb8fd503-da7a-4d0c-ee58-6aef98132d08"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 2, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHSIZMLtf6h0",
        "outputId": "9163cab5-046c-4ea6-d58f-2733dee8159a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 0 - BASELINE\n",
        "Our first model we'll be a TF-IDF Multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "Xoxirnefg987"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "model_0.fit(X = train_sentences, y = train_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Edg6_HPkg7dQ",
        "outputId": "ce2be6c3-7833-45ca-9159-a7d2bcd2658d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.score(X = val_sentences, y = val_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohctBiYuiXHh",
        "outputId": "a4c285ef-859b-4e5b-fef5-0584aebdcf23"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7418429420710632"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nice. 74 per cent accuracy in the first time. Not Bad"
      ],
      "metadata": {
        "id": "V1jxqXDyi2DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSVMD-eUjHac",
        "outputId": "8ce849a1-aa79-4d08-cb27-0a5c08b78c24"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-12 01:14:44--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-12 01:14:44 (111 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import calculate_results helper function\n",
        "from helper_functions import calculate_results"
      ],
      "metadata": {
        "id": "OAiutJBnjJ3w"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZyVWw5ljZ_7",
        "outputId": "ab8baaaa-5bf5-42e9-a4b8-dfe5a0fac619"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 4, 4, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN1tWG_8jTmi",
        "outputId": "4a65105f-dbfe-4f24-b53e-85a22ae35591"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 74.18429420710632,\n",
              " 'precision': 0.7360346052083626,\n",
              " 'recall': 0.7418429420710632,\n",
              " 'f1': 0.7276693500802428}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LET'S PREPARE THE DATA FOR DEEP SEQUENCE MODELS"
      ],
      "metadata": {
        "id": "V8GC5ULmo3QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "Ioo4x7eJo61P"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# How long is each sentence on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len # return average sentence length (in tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP7EVh0ppO9h",
        "outputId": "5871f9e1-2736-4486-bdfd-527d0db0e2b4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.213070187216427"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=10);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "dJA1rNGOpS5n",
        "outputId": "dcc1c1ce-feba-48e9-f434-7b01c8bc6949"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLv2XHCApgwb",
        "outputId": "b8b5c339-93b7-4957-fa22-0a17ec448d70"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOW WE WILL CREATE TEXT VECTORIZER"
      ],
      "metadata": {
        "id": "d4r5siHZsDne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens = 130000"
      ],
      "metadata": {
        "id": "FVLe-NvqsG5p"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "text_vectorizer = TextVectorization(max_tokens = max_tokens , output_sequence_length =54)\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "rUYFb4_6sZc9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1XpD_duqsZH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test out text vectorizer\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUqCWpt-UxHR",
        "outputId": "b1fd2d03-e6d5-489d-9795-205e3f3ef795"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "a multicenter trial with greater statistical power would be needed to demonstrate a benefit for this drug .\n",
            "\n",
            "Length of text: 18\n",
            "\n",
            "Vectorized text:\n",
            "[[   8  488   40    7  165  478  878  479   39  525    6 1104    8  365\n",
            "    12   24  250    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words in our training vocabulary?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"),\n",
        "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")\n"
      ],
      "metadata": {
        "id": "A8c1hTxTGSKF",
        "outputId": "fa5823f2-ee2c-4d0a-f249-831378e1a416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocabulary: 130000\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'the', 'of', 'and']\n",
            "Least common words in the vocabulary: ['canc', 'canbesure', 'canaud', 'canastota', 'canasa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rct_200k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"),\n",
        "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEgCdqllTsut",
        "outputId": "d920bb96-f7f2-43a6-e1fd-16b53e3ec1c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocabulary: 130000\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'the', 'of', 'and']\n",
            "Least common words in the vocabulary: ['canc', 'canbesure', 'canaud', 'canastota', 'canasa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_4tK43JT-gZ",
        "outputId": "5f23bbfc-1f6a-4e21-d888-6aac6b09da4a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization',\n",
              " 'trainable': True,\n",
              " 'dtype': 'string',\n",
              " 'batch_input_shape': (None,),\n",
              " 'max_tokens': 130000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 54,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 130000}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "token_embed = layers.Embedding(input_dim=len(rct_200k_text_vocab), # length of vocabulary\n",
        "                               output_dim=128, # Note: different embedding sizes result in drastically different numbers of parameters to train\n",
        "                               # Use masking to handle variable sequence lengths (save space)\n",
        "                               mask_zero=True,\n",
        "                               name=\"token_embedding\")\n",
        "\n",
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kud9WhYXT1DX",
        "outputId": "66fda45e-141e-45e6-ea28-9b94db6621d4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization:\n",
            "a multicenter trial with greater statistical power would be needed to demonstrate a benefit for this drug .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            "[[   8  488   40    7  165  478  878  479   39  525    6 1104    8  365\n",
            "    12   24  250    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "Sentence after embedding:\n",
            "[[[-0.03708888 -0.00054516 -0.01045937 ... -0.04259888  0.00207516\n",
            "   -0.01842902]\n",
            "  [-0.02110673 -0.03245313  0.04906828 ...  0.03443367 -0.00443746\n",
            "   -0.0252359 ]\n",
            "  [-0.01953825 -0.00596465 -0.02291117 ... -0.03145695  0.0311848\n",
            "   -0.03620564]\n",
            "  ...\n",
            "  [ 0.04096461 -0.04558894 -0.03200852 ...  0.04520421 -0.02790705\n",
            "    0.04654875]\n",
            "  [ 0.04096461 -0.04558894 -0.03200852 ...  0.04520421 -0.02790705\n",
            "    0.04654875]\n",
            "  [ 0.04096461 -0.04558894 -0.03200852 ...  0.04520421 -0.02790705\n",
            "    0.04654875]]]\n",
            "\n",
            "Embedded sentence shape: (1, 54, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOW WE WILL USE TF.DATA API. THIS IS TO HANDLE THE DATA BETTER"
      ],
      "metadata": {
        "id": "l9Vbq7MTVczG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_9W0mAfWMYy",
        "outputId": "19d0f3e2-e39a-457a-a5b1-05cff1774089"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWZyt3kJWPqf",
        "outputId": "61f4a7d7-3939-47cb-f31d-cd3c60ea428e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 1 : CONV1D WITH TOKEN EMBEDDING\n",
        "\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)"
      ],
      "metadata": {
        "id": "9B3C8ma8WSEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs)\n",
        "token_embeddings = token_embed(text_vectors)\n",
        "\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, padding = \"same\" , activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_conv1d\")\n",
        "\n",
        "#Compiling the model\n",
        "\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "lU82Gg83WmpN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce9yOd1lXqFh",
        "outputId": "3145dcb2-ac1a-4ba9-def6-e5e6021b20eb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_conv1d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 54)                0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " token_embedding (Embedding  (None, 54, 128)           16640000  \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 54, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 64)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681349 (63.63 MB)\n",
            "Trainable params: 16681349 (63.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odel_1_history = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x58B5J5lX5qs",
        "outputId": "ab997dc9-c44c-4eef-d2d8-a551fd3697de"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2350/2350 [==============================] - 469s 199ms/step - loss: 0.6150 - accuracy: 0.7792 - val_loss: 0.5536 - val_accuracy: 0.7993\n",
            "Epoch 2/3\n",
            "2350/2350 [==============================] - 469s 199ms/step - loss: 0.5501 - accuracy: 0.8066 - val_loss: 0.5210 - val_accuracy: 0.8128\n",
            "Epoch 3/3\n",
            "2350/2350 [==============================] - 469s 200ms/step - loss: 0.5390 - accuracy: 0.8096 - val_loss: 0.4984 - val_accuracy: 0.8212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 2 - FEATURE EXTRACTION WITH PRETRAINED TOKEN EMBEDDINGS"
      ],
      "metadata": {
        "id": "ii-OKbcyb64o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "metadata": {
        "id": "bUE_vqOBcAbW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
        "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1vfykSAeUdF",
        "outputId": "b9b90d43-e07e-493b-9d61-2600c7a934b5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random training sentence:\n",
            "women ( n = @ ) undergoing follicular stimulation for in vitro fertilization , using long-course analog therapy to suppress endogenous luteinizing hormone ( lh ) , were randomly allocated to a short ( @ hour ) or long ( @ hour ) delay between human chorionic gonadotropin ( hcg ) administration and oocyte retrieval .\n",
            "\n",
            "Sentence after embedding:\n",
            "[-0.0589774  -0.03475577 -0.00083291  0.00956164 -0.01512722  0.01827455\n",
            "  0.04120813 -0.04877249  0.01947647  0.00356439  0.07470762 -0.05664556\n",
            "  0.07222613  0.03516386  0.07495824 -0.01605282 -0.07798145  0.03785181\n",
            " -0.04643878  0.07256775  0.02083915  0.00243232  0.04979791  0.0339425\n",
            "  0.04774152  0.00212047 -0.02122561  0.03165422 -0.06230999  0.01445855] (truncated output)...\n",
            "\n",
            "Length of sentence embedding:\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define feature extractor model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "# Note: you could add more layers here if you wanted to\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
        "model_2 = tf.keras.Model(inputs=inputs,\n",
        "                        outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        ""
      ],
      "metadata": {
        "id": "syDHC251fED8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(train_dataset,\n",
        "            steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "            epochs=3,\n",
        "            validation_data=valid_dataset,\n",
        "            validation_steps=int(0.1 * len(valid_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mwM5eiqfIkg",
        "outputId": "10f9b0d9-1f26-4a63-ebe7-ca5c14a5e76c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2350/2350 [==============================] - 21s 8ms/step - loss: 0.7585 - accuracy: 0.7112 - val_loss: 0.6818 - val_accuracy: 0.7427\n",
            "Epoch 2/3\n",
            "2350/2350 [==============================] - 18s 8ms/step - loss: 0.6748 - accuracy: 0.7425 - val_loss: 0.6550 - val_accuracy: 0.7497\n",
            "Epoch 3/3\n",
            "2350/2350 [==============================] - 18s 8ms/step - loss: 0.6517 - accuracy: 0.7539 - val_loss: 0.6218 - val_accuracy: 0.7625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a300c7bfc10>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 3 : CONV1D with character embeddings"
      ],
      "metadata": {
        "id": "p28rZw7JfS9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Test splitting non-character-level sequence into characters\n",
        "split_chars(random_training_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "5uRW4pzofZXu",
        "outputId": "7e19e4b9-fd69-4471-f6e5-4b8aae246062"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'w o m e n   (   n   =   @   )   u n d e r g o i n g   f o l l i c u l a r   s t i m u l a t i o n   f o r   i n   v i t r o   f e r t i l i z a t i o n   ,   u s i n g   l o n g - c o u r s e   a n a l o g   t h e r a p y   t o   s u p p r e s s   e n d o g e n o u s   l u t e i n i z i n g   h o r m o n e   (   l h   )   ,   w e r e   r a n d o m l y   a l l o c a t e d   t o   a   s h o r t   (   @   h o u r   )   o r   l o n g   (   @   h o u r   )   d e l a y   b e t w e e n   h u m a n   c h o r i o n i c   g o n a d o t r o p i n   (   h c g   )   a d m i n i s t r a t i o n   a n d   o o c y t e   r e t r i e v a l   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "print(train_chars[0])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T1p1_zJgvAs",
        "outputId": "52ce350f-bdcf-4e28-d727-c2717ae0fa4a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t h e   e m e r g e n c e   o f   h i v   a s   a   c h r o n i c   c o n d i t i o n   m e a n s   t h a t   p e o p l e   l i v i n g   w i t h   h i v   a r e   r e q u i r e d   t o   t a k e   m o r e   r e s p o n s i b i l i t y   f o r   t h e   s e l f - m a n a g e m e n t   o f   t h e i r   c o n d i t i o n   ,   i n c l u d i n g   m a k i n g   p h y s i c a l   ,   e m o t i o n a l   a n d   s o c i a l   a d j u s t m e n t s   .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the average character length?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E76a2WkFgyjM",
        "outputId": "8c464370-b657-45e3-b865-57720eaba045"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147.75132107025635"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find what character length covers 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giahJKMtg3sp",
        "outputId": "4bfc38c3-7e04-4a06-c2bb-e205310267ab"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "284"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pUCz4cjxjcuZ",
        "outputId": "3e227eb4-b897-4aef-8edf-a7d10a525078"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "FqoAun4jjieS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check character vocabulary characteristics\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbmOsqZWjj3s",
        "outputId": "4f4422e7-af1c-4c1e-f1e9-f7519439f07c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different characters in character vocab: 28\n",
            "5 most common characters: ['', '[UNK]', 'e', 't', 'a']\n",
            "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n{random_train_chars}\")\n",
        "print(f\"\\nLength of chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY5uTJuKmBTr",
        "outputId": "f43bec7e-fa97-480e-ac87-ef7b9b3fd0cb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            "r a n d o m i z e d   c o n t r o l l e d   c l i n i c a l   t r i a l   .\n",
            "\n",
            "Length of chars: 34\n",
            "\n",
            "Vectorized chars:\n",
            "[[ 8  4  6 10  7 15  5 25  2 10 12  7  6  3  8  7 11 11  2 10 12 11  5  6\n",
            "   5 12  4 11  3  8  5  4 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "\n",
            "Length of vectorized chars: 284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=False, # don't use masks (this messes up model_5 if set to True)\n",
        "                              name=\"char_embed\")\n",
        "\n",
        "# Test out character embedding layer\n",
        "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAxpXBFTl7ss",
        "outputId": "6986cb0b-bd3c-42f0-ac66-ccfc805338bf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text (before vectorization and embedding):\n",
            "r a n d o m i z e d   c o n t r o l l e d   c l i n i c a l   t r i a l   .\n",
            "\n",
            "Embedded chars (after vectorization and embedding):\n",
            "[[[ 0.00382981  0.0101524  -0.03034792 ... -0.00240079 -0.00153934\n",
            "   -0.00475602]\n",
            "  [-0.03931282 -0.01068153 -0.03095348 ... -0.04020824 -0.00233561\n",
            "    0.03369728]\n",
            "  [ 0.02100253  0.02418219  0.04219437 ... -0.04686303 -0.01923008\n",
            "    0.03657273]\n",
            "  ...\n",
            "  [-0.0482482  -0.03520826  0.00940493 ... -0.02940215 -0.01584723\n",
            "   -0.02132385]\n",
            "  [-0.0482482  -0.03520826  0.00940493 ... -0.02940215 -0.01584723\n",
            "   -0.02132385]\n",
            "  [-0.0482482  -0.03520826  0.00940493 ... -0.02940215 -0.01584723\n",
            "   -0.02132385]]]\n",
            "\n",
            "Character embedding shape: (1, 284, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=28, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=False, # don't use masks (this messes up model_5 if set to True)\n",
        "                              name=\"char_embed\")\n",
        "\n",
        "# Test out character embedding layer\n",
        "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lXafThlnbgs",
        "outputId": "68517eb5-8c55-4667-d65a-8b05ef007acd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text (before vectorization and embedding):\n",
            "r a n d o m i z e d   c o n t r o l l e d   c l i n i c a l   t r i a l   .\n",
            "\n",
            "Embedded chars (after vectorization and embedding):\n",
            "[[[ 0.01831894 -0.03906078 -0.02030867 ... -0.03471979  0.00350926\n",
            "   -0.00186646]\n",
            "  [-0.02957604  0.03692683 -0.01410443 ... -0.02650908  0.0106109\n",
            "   -0.0373799 ]\n",
            "  [ 0.04748836  0.00873057  0.00452399 ... -0.01562244  0.02727335\n",
            "    0.0005947 ]\n",
            "  ...\n",
            "  [ 0.00842541 -0.03857852 -0.04436171 ... -0.03931745  0.0171659\n",
            "   -0.02909153]\n",
            "  [ 0.00842541 -0.03857852 -0.04436171 ... -0.03931745  0.0171659\n",
            "   -0.02909153]\n",
            "  [ 0.00842541 -0.03857852 -0.04436171 ... -0.03931745  0.0171659\n",
            "   -0.02909153]]]\n",
            "\n",
            "Character embedding shape: (1, 284, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"model_3_conv1D_char_embedding\")\n",
        "\n",
        "# Compile model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "5f9bUcRIng4m"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS0yE1bhnlXc",
        "outputId": "c3fdbc3e-0637-4242-e26e-f9a0e03df7e5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkQQ1FEmnoD4",
        "outputId": "6b8a6b93-5841-4c0b-9503-4bd31fe10ef3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2350/2350 [==============================] - 15s 6ms/step - loss: 0.9831 - accuracy: 0.6135 - val_loss: 0.8193 - val_accuracy: 0.6944\n",
            "Epoch 2/3\n",
            "2350/2350 [==============================] - 14s 6ms/step - loss: 0.7978 - accuracy: 0.6961 - val_loss: 0.7581 - val_accuracy: 0.7177\n",
            "Epoch 3/3\n",
            "2350/2350 [==============================] - 14s 6ms/step - loss: 0.7597 - accuracy: 0.7124 - val_loss: 0.7287 - val_accuracy: 0.7285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 4: Combining pretrained token embeddings + character embeddings (hybrid embedding layer)"
      ],
      "metadata": {
        "id": "uvSZ268On3-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output,\n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(token_char_concat) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"model_4_token_and_char_embeddings\")"
      ],
      "metadata": {
        "id": "i4YezabMn41_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions using SGD but we'll stick with Adam\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "WxusOt6ktH54"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Repeat same steps validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        ""
      ],
      "metadata": {
        "id": "LvwtHJgBtLs6"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_history = model_4.fit(train_char_token_dataset, # train on dataset of token and characters\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_token_dataset)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ-BwGP7tQDG",
        "outputId": "1b44d259-a4f9-4e2b-feb6-afdbcf39c701"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2350/2350 [==============================] - 220s 92ms/step - loss: 0.7264 - accuracy: 0.7234 - val_loss: 0.6127 - val_accuracy: 0.7639\n",
            "Epoch 2/3\n",
            "2350/2350 [==============================] - 216s 92ms/step - loss: 0.6345 - accuracy: 0.7600 - val_loss: 0.5907 - val_accuracy: 0.7764\n",
            "Epoch 3/3\n",
            "2350/2350 [==============================] - 217s 92ms/step - loss: 0.6154 - accuracy: 0.7707 - val_loss: 0.5718 - val_accuracy: 0.7882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"line_number\" column\n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)\n",
        ""
      ],
      "metadata": {
        "id": "-_wpswwpzPgl"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_line_numbers_one_hot.shape, train_line_numbers_one_hot[:20]\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFrASUYszR89",
        "outputId": "c0c563d6-afae-4b0a-9e5f-3e6c79ad6fbd"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([752231, 15]),\n",
              " <tf.Tensor: shape=(20, 15), dtype=float32, numpy=\n",
              " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "\n",
        "# Check shape and samples of total lines one-hot tensor\n",
        "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM6f8iY5zYKm",
        "outputId": "6d111a3a-f488-4f15-9d6e-6dbd26e437b0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([752231, 20]),\n",
              " <tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
              " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.percentile(train_df.total_lines, 98) # a value of 20 covers 98% of samples\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmway9taziTe",
        "outputId": "95337fc4-5af3-4fb7-f73d-f8ccf4c6f52a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.0"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)\n",
        ""
      ],
      "metadata": {
        "id": "bjXuYU7zzr3B"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Token inputs\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "\n",
        "# 2. Char inputs\n",
        "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Line numbers inputs\n",
        "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)\n",
        "\n",
        "# 4. Total lines inputs\n",
        "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                  outputs=y)\n",
        "\n",
        "# 5. Combine token and char embeddings into a hybrid embedding\n",
        "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output,\n",
        "                                                                              char_model.output])\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
        "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
        "                                                                total_line_model.output,\n",
        "                                                                z])\n",
        "\n",
        "# 7. Create output layer\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# 8. Put together model\n",
        "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input,\n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer)\n",
        ""
      ],
      "metadata": {
        "id": "r_GoAilrzy71"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.15), # add label smoothing (examples which are really confident get smoothed a little)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "sLgU9gcqz5GD"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the token, char and positional embedding model\n",
        "history_model_5 = model_5.fit(train_pos_char_token_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_pos_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGxftc3Nz_ZY",
        "outputId": "30aa9f09-6ad1-4d67-d02b-9ba6a7b745b2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2350/2350 [==============================] - 227s 95ms/step - loss: 0.8877 - accuracy: 0.8034 - val_loss: 0.8223 - val_accuracy: 0.8406\n",
            "Epoch 2/3\n",
            "2350/2350 [==============================] - 221s 94ms/step - loss: 0.8230 - accuracy: 0.8437 - val_loss: 0.8087 - val_accuracy: 0.8569\n",
            "Epoch 3/3\n",
            "2350/2350 [==============================] - 218s 93ms/step - loss: 0.8176 - accuracy: 0.8479 - val_loss: 0.8010 - val_accuracy: 0.8597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation datasets (all four kinds of inputs)\n",
        "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # line numbers\n",
        "                                                                train_total_lines_one_hot, # total lines\n",
        "                                                                train_sentences, # train tokens\n",
        "                                                                train_chars)) # train chars\n",
        "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # train labels\n",
        "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n",
        "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Validation dataset\n",
        "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                              val_total_lines_one_hot,\n",
        "                                                              val_sentences,\n",
        "                                                              val_chars))\n",
        "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
        "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Check input shapes\n",
        "train_pos_char_token_dataset, val_pos_char_token_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id2RBBhUz-LO",
        "outputId": "ad34aea7-cb54-4458-c02f-5a58fa5f9504"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>,\n",
              " <_PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_pred_probs = model_5.predict(val_pos_char_token_dataset, verbose=1)\n",
        "model_5_pred_probs\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIs-Wtc80Pct",
        "outputId": "5dac2567-abf7-4b62-8e15-a6dcfa50eb3b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "905/905 [==============================] - 24s 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.46765733, 0.04570586, 0.04183071, 0.3501139 , 0.09469216],\n",
              "       [0.15995023, 0.02686261, 0.5269808 , 0.22658232, 0.05962408],\n",
              "       [0.20456278, 0.03108138, 0.2469467 , 0.12727828, 0.39013076],\n",
              "       ...,\n",
              "       [0.05430468, 0.38007593, 0.04989479, 0.04222756, 0.47349715],\n",
              "       [0.03406326, 0.34425205, 0.10745772, 0.03248947, 0.48173746],\n",
              "       [0.03368073, 0.85332805, 0.01444742, 0.02404651, 0.07449733]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duPbc6xe0Re6",
        "outputId": "73129855-8435-40ca-f943-58db81a840eb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(28932,), dtype=int64, numpy=array([0, 2, 4, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results of token-char-positional hybrid model\n",
        "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbj-eLPJ0TDP",
        "outputId": "d5ea05bd-3bd3-48dd-f1e7-6deb5976d997"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 85.6283699709664,\n",
              " 'precision': 0.855959740736961,\n",
              " 'recall': 0.856283699709664,\n",
              " 'f1': 0.8549406008369356}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THIS IS THE BEST PERFORMING MODEL . YOU CAN MAKE NECASSARY CHANGES ; AND TRY TO IMPROVE THE MODEL ACCURACY"
      ],
      "metadata": {
        "id": "bHfCz7Bx3ALt"
      }
    }
  ]
}